{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AB7qsWVOAg8I"
      },
      "source": [
        "# 1.COLECCION GUTENBERG"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-f6j9GseBX1G"
      },
      "source": [
        "Busque en la colección Gutenberg (https://www.gutenberg.org/) los 3 tomos en español de\n",
        "“Las mil y una noches” (autor anónimo)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "p1QcGaBNG3xu"
      },
      "outputs": [],
      "source": [
        "'''Almacenamos las URL de los tomos de\n",
        "   \"Las mil y una noches\" en el espacio\n",
        "   de nombres de Python'''\n",
        "\n",
        "tomo1 = 'https://www.gutenberg.org/cache/epub/47287/pg47287-images.html'\n",
        "tomo2 = 'https://www.gutenberg.org/cache/epub/47631/pg47631-images.html'\n",
        "tomo3 = 'https://www.gutenberg.org/cache/epub/48903/pg48903-images.html'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qAIfkgiVBDCE"
      },
      "source": [
        "# 2.WEB SCRAPING"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "awr0s4k2Bb1N"
      },
      "source": [
        "Recupere la información desde las páginas web"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JiZxvVeIKESS"
      },
      "source": [
        "Una vez que tenemos las URL de los tres tomos. Debemos obtener el texto, del HTML, del sitio web. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xUytc53SH8Jz",
        "outputId": "f29b892c-6849-4292-ae18-fdc1d7c8e907"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  The Project Gutenberg eBook of Las mil noches y una noche; t. 1.\n",
            "\n",
            "\n",
            "  The Project Gutenberg eBook of El libro de las mil noches y una noche; t. 2, by\n",
            "Anonymous\n",
            "\n",
            "\n",
            "  The Project Gutenberg eBook of El libro de las mil noches y una noche; t. 3\n",
            "\n"
          ]
        }
      ],
      "source": [
        "'''Obtenemos el texto del sitio web de los tres tomos\n",
        "   Reaizamos una solicitud de los datos usando requests\n",
        "   y verificamos el tipo de objeto'''\n",
        "\n",
        "# Importar `requests`\n",
        "import requests\n",
        "# Importar Beautiful Soup\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "\n",
        "def extraerText(URL):\n",
        "  # Hacer el requests (Solicitud para acceder a los datos)\n",
        "  r = requests.get(URL)\n",
        "  # Verificar que el tipo de objeto sea Response\n",
        "  if type(r) is requests.models.Response:\n",
        "    # Extraemos HTML del objeto \n",
        "    html = r.text\n",
        "  # Crear un objeto de BeautifulSoup object desde el HTML\n",
        "  soup = BeautifulSoup(html, \"html5lib\")\n",
        "  # imprimir el titulo\n",
        "  print(soup.title.string)\n",
        "  # obtener el texto de soup y retornarlo\n",
        "  text = soup.get_text()\n",
        "  return (text)\n",
        "\n",
        "# Extraemos el texto de los tres tomos de \"Las mil y una noches\"\n",
        "text1 = extraerText(tomo1)\n",
        "text2 = extraerText(tomo2)\n",
        "text3 = extraerText(tomo3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ffHIh3jQFs5D",
        "outputId": "fa146e9b-e11d-46a3-f0ca-63f94db0712e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "text1: 384458\n",
            "text2: 321929\n",
            "text3: 321929\n"
          ]
        }
      ],
      "source": [
        "# Verificamos su dimension\n",
        "print(f\"text1: {len(text1)}\")\n",
        "print(f\"text2: {len(text3)}\")\n",
        "print(f\"text3: {len(text3)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_7UR5GvBgwa"
      },
      "source": [
        "# 3.LIMPIANDO EL TEXTO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZwjriHdHBrf2"
      },
      "source": [
        "Elimine de los textos todo el contenido que no pertenezca a la obra (links, información\n",
        "sobre el proyecto Gutenberg, índices, caracteres de adorno, líneas en blanco, etc.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YovzaRDWLx4N"
      },
      "source": [
        "#### **gutenberg-cleaner**: \n",
        "Es una libreria para limpiar libros y un conjunto de datos del proyecto Gutenberg\n",
        "* Consta de dos metodos:\n",
        "  1. simple_claner: Elimina la parte del encabezado y el pie de la pagina. No profundiza en el texto para eliminar otras cosas como títulos o notas al pie\n",
        "  `simple_cleaner(libro: str) -> str `\n",
        "  2. super_cleaner: Puede eliminar algunas buenas líneas también, dependiendo de los tokens minimos de un parrafo que noe sdialogo o cita.\n",
        "  `super_cleaner(libro: str, min_token: int = 5, max_token: int = 600) -> str `\n",
        "\n",
        "#### **re**:\n",
        "Es una libreria para expresiones regulares de python utilizado para especificar las reglas de las cadenas de caracteres posibles que se desea hacer coincidir."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "plggOw9PT75D",
        "outputId": "05f50bba-c0ec-46d7-a4c7-bef1d4373624"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gutenberg-cleaner in /usr/local/lib/python3.7/dist-packages (0.1.6)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from gutenberg-cleaner) (3.7)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk->gutenberg-cleaner) (4.64.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.7/dist-packages (from nltk->gutenberg-cleaner) (2022.6.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk->gutenberg-cleaner) (1.2.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk->gutenberg-cleaner) (7.1.2)\n"
          ]
        }
      ],
      "source": [
        "# instalando la libreria gutenberg-cleaner\n",
        "!pip install gutenberg-cleaner"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "T3YDd1pMB5Gg"
      },
      "outputs": [],
      "source": [
        "from gutenberg_cleaner import simple_cleaner, super_cleaner\n",
        "import re\n",
        "def limpiarGutemberg(text):\n",
        "  # --  Eliminando informacion Gutenberg: cabeceras, indices, notas\n",
        "  text = simple_cleaner(text)\n",
        "  # -- Eliminando espacios en blanco\n",
        "  text = text.strip()\n",
        "  # -- Eliminando lineas en blanco\n",
        "  text = text.replace('\\r', '').replace('\\n', '')\n",
        "  # -- Eliminando enlaces\n",
        "  text = re.sub(r'''(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:'\".,<>?«»“”‘’]))''', \" \", text)\n",
        "  # -- Eliminando simbolos especiales\n",
        "  text = re.sub(r'[^\\w\\s]', ' ', text)\n",
        "  # -- retornando texto limpio\n",
        "  return text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "xik5Sp8tDGSq"
      },
      "outputs": [],
      "source": [
        "# Limpiar el texto de los tres tomos de \"Las mil y una noches\"\n",
        "text1 = limpiarGutemberg(text1)\n",
        "text2 = limpiarGutemberg(text2)\n",
        "text3 = limpiarGutemberg(text3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q_1N4Z1bE6P1",
        "outputId": "072650d4-8b98-4b7d-8a25-a4f9498484cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "text1: 372386\n",
            "text2: 312116\n",
            "text3: 312116\n"
          ]
        }
      ],
      "source": [
        "# Verificamos su dimension\n",
        "print(f\"text1: {len(text1)}\")\n",
        "print(f\"text2: {len(text3)}\")\n",
        "print(f\"text3: {len(text3)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_h7PV2abBs9w"
      },
      "source": [
        "# 4.TEXT RAW"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6BzOUuE0ByIK"
      },
      "source": [
        "Junte los tres tomos en un solo texto"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rmf7Wg1hEOa-",
        "outputId": "9a1d3bbd-0678-4323-df4e-4bf153929a08"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1004231"
            ]
          },
          "execution_count": 102,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Concatenamos los textos \n",
        "text = text1 + text2 + text3\n",
        "len(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3iI1LiugB1mu"
      },
      "source": [
        "# 5.TOKENIZACION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sAyOx3eiDCzd"
      },
      "source": [
        "## MODULOS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s05Gv1ccB5yM"
      },
      "source": [
        "Crear los módulos necesarios para:\n",
        "\n",
        "    a. Recuperar una historia por su título.\n",
        "\n",
        "    b. Dividir (tokenizar) el texto por historias.\n",
        "\n",
        "    c. Dividir (tokenizar) el texto por párrafos.\n",
        "\n",
        "    d. Dividir (tokenizar) el texto por oraciones.\n",
        "\n",
        "    e. Tokenizar el texto en palabras."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HOgjXbJUCXDR"
      },
      "source": [
        "### a. Recuperar una historia por su título."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FXCfBZn4kvGl"
      },
      "outputs": [],
      "source": [
        "def RecuperarHistoria(titulo):\n",
        "  \n",
        "  return historia"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "QpsJEU4yGDdt",
        "outputId": "51bc16e3-3021-4349-c40a-cfac87190cc1"
      },
      "outputs": [
        {
          "ename": "FeatureNotFound",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFeatureNotFound\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-109-8b73ef0e2c73>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mtomo1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'https://www.gutenberg.org/cache/epub/47287/pg47287-images.html'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mpage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtomo1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0msoup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'HISTORIA DEL REY SCHAHRIAR Y DE SU HERMANO El REY SCHAHZAMAN'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m data.append({\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/bs4/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, markup, features, builder, parse_only, from_encoding, exclude_encodings, **kwargs)\u001b[0m\n\u001b[1;32m    196\u001b[0m                     \u001b[0;34m\"Couldn't find a tree builder with the features you \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0;34m\"requested: %s. Do you need to install a parser library?\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m                     % \",\".join(features))\n\u001b[0m\u001b[1;32m    199\u001b[0m             \u001b[0mbuilder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuilder_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m             if not (original_features == builder.NAME or\n",
            "\u001b[0;31mFeatureNotFound\u001b[0m: Couldn't find a tree builder with the features you requested: HISTORIA DEL REY SCHAHRIAR Y DE SU HERMANO El REY SCHAHZAMAN. Do you need to install a parser library?"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "data = []\n",
        "\n",
        "# Make a request\n",
        "tomo1 = 'https://www.gutenberg.org/cache/epub/47287/pg47287-images.html'\n",
        "page = requests.get(tomo1)\n",
        "soup = BeautifulSoup(page.content, 'html.parser')\n",
        "\n",
        "data.append({\n",
        "    'title': soup.title,\n",
        "    'chapter': soup.h2.get_text(),\n",
        "    'text': ' '.join([p.get_text(strip=True) for p in soup.select('body p')[2:]])\n",
        "    }\n",
        ")\n",
        "\n",
        "print(data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nT9r23QgCnY9"
      },
      "source": [
        "### b. Dividir (tokenizar) el texto por historias."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B51z09jpCrQ7"
      },
      "source": [
        "### c. Dividir (tokenizar) el texto por párrafos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q86jMXrNCwhF"
      },
      "source": [
        "### d. Dividir (tokenizar) el texto por oraciones."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4-QUpMjAC0IR"
      },
      "source": [
        "### e. Tokenizar el texto en palabras."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5mvdU9DsC3F3"
      },
      "source": [
        "## PRUEBAS\n",
        "Realice las pruebas pertinentes de cada módulo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iL-Khuw3DRW1"
      },
      "source": [
        "# 6.NORMALIZACION "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x43NYf3iDtqZ"
      },
      "source": [
        "## MODULOS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vIuznevuD1ch"
      },
      "source": [
        "Crear lo siguientes módulos independientes para normalizar un texto:\n",
        "\n",
        "a. Quitar signos de puntuación\n",
        "\n",
        "b. Convertir a minúsculas\n",
        "\n",
        "c. Quitar stop-words\n",
        "\n",
        "d. Quitar palabras con extensión mínima (valor por defecto del parámetro: 2)\n",
        "\n",
        "e. Lematizar\n",
        "\n",
        "f. Eliminar duplicados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6K-VtIBD6Mr"
      },
      "source": [
        "### a. Quitar signos de puntuación"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sWMX1h9jD-2Z"
      },
      "source": [
        "### b. Convertir a minúsculas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CwZWFF5tEAy9"
      },
      "source": [
        "### c. Quitar stop-words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x8_IUwB1EJyU"
      },
      "source": [
        "### d. Quitar palabras con extensión mínima"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s3e_7RMAEMTn"
      },
      "source": [
        "### e. Lematizar"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mh01z6Z0EQMK"
      },
      "source": [
        "### f. Eliminar duplicados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "afD0hbs4EWMV"
      },
      "source": [
        "## SECUENCIA DE MODULOS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "piTteXhBEbVg"
      },
      "source": [
        "### Secuencia 1\n",
        "a. Quitar signos de puntuación\n",
        "\n",
        "b. Convertir a minúsculas\n",
        "\n",
        "c. Quitar stop-words\n",
        "\n",
        "d. Quitar palabras con extensión mínima\n",
        "\n",
        "e. Lematizar\n",
        "\n",
        "f. Eliminar duplicados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "927Dhgf0EhD-"
      },
      "source": [
        "### Secuencia 2\n",
        "a. Quitar signos de puntuación\n",
        "\n",
        "b. Convertir a minúsculas\n",
        "\n",
        "c. Quitar palabras con extensión mínima\n",
        "\n",
        "d. Quitar stop-words\n",
        "\n",
        "e. Lematizar\n",
        "\n",
        "f. Eliminar duplicados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X4RULyOqEhXS"
      },
      "source": [
        "### Secuencia 3\n",
        "a. Lematizar\n",
        "\n",
        "b. Quitar signos de puntuación\n",
        "\n",
        "c. Convertir a minúsculas\n",
        "\n",
        "d. Quitar stop-words\n",
        "\n",
        "e. Quitar palabras con extensión mínima\n",
        "\n",
        "f. Eliminar duplicados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDan0c5fFQ8G"
      },
      "source": [
        "### Secuencia 4\n",
        "a. Lematizar\n",
        "\n",
        "b. Quitar signos de puntuación\n",
        "\n",
        "c. Convertir a minúsculas\n",
        "\n",
        "d. Quitar stop-words\n",
        "\n",
        "e. Quitar palabras con extensión mínima\n",
        "\n",
        "f. Eliminar duplicados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4PSG9a6SFRPQ"
      },
      "source": [
        "### Secuencia 5\n",
        "a. Lematizar\n",
        "\n",
        "b. Quitar signos de puntuación\n",
        "\n",
        "c. Convertir a minúsculas\n",
        "\n",
        "d. Quitar stop-words\n",
        "\n",
        "e. Quitar palabras con extensión mínima\n",
        "\n",
        "f. Eliminar duplicados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p38oOktiFYTg"
      },
      "source": [
        "## ANALISIS DE RESULTADOS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3rvO0VuFf8Z"
      },
      "source": [
        "## CONCLUSIONES"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjUCrTIKFidz"
      },
      "source": [
        "# 7. CORPUS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QhuqmPGEFul9"
      },
      "source": [
        "Convertir los textos planos (textoRAW) a un corpus propiamente dicho, mediante el uso de\n",
        "librerías como PlaintextCorpusReader. Comparar los resultados obtenidos con lo\n",
        "\n",
        "implementado en los puntos 5 y 6 (realizar las pruebas necesarias para la comparación,\n",
        "explicando adecuadamente la secuencia)."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3.9.13 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "dc07d24e2f18896857f0b2a651fe84ba40ce7b297e58d8804a308c8039f752a6"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
